Generate exactly {count} RAG (Retrieval-Augmented Generation) test scenarios for the topic: "{topic}".

Return a JSON object with a single key "scenarios" containing an array.
Each element MUST have this exact schema (4 flat text fields, CSV-compatible):
{{
  "scenarios": [
    {{
      "id": "RAG_001",
      "query": "A realistic user question about the topic",
      "context": "One or more paragraphs of retrieved context that contain relevant information. This should be 2-5 sentences of realistic domain text.",
      "ground_truth": "The correct answer that can be fully derived from the context."
    }}
  ]
}}

IMPORTANT RULES:
1. ALL scenarios must be domain-specific to "{topic}"
2. Context passages must be realistic and contain enough detail to answer the query
3. Ground truth must be FULLY derivable from the context (no external knowledge needed)
4. Include at least 1 scenario where context is INSUFFICIENT to fully answer the query
5. Include at least 1 scenario with CONTRADICTORY information in the context
6. Mix query complexity: simple factual, multi-hop reasoning, and synthesis
7. Queries should be natural and varied
8. Context should simulate real retrieved documents (policies, manuals, FAQs, articles)
9. Return ONLY the JSON object with "scenarios" key - no markdown fences, no explanation
10. The "scenarios" array MUST contain EXACTLY {count} items - not more, not less
